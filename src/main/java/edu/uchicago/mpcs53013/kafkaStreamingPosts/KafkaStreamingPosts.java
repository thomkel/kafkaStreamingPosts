package edu.uchicago.mpcs53013.kafkaStreamingPosts;

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import scala.Function1;
import scala.Tuple2;
import scala.runtime.AbstractFunction1;
import edu.uchicago.mpcs53013.PostSummary.PostSummary;


import com.google.common.collect.Lists;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaPairReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.kafka.KafkaUtils;

import java.io.Serializable;
import java.util.Date;
import java.util.HashMap;
import java.util.regex.Pattern;

import com.datastax.driver.core.Cluster;
import com.datastax.driver.core.Host;
import com.datastax.driver.core.Metadata;
import com.datastax.driver.core.ResultSet;
import com.datastax.driver.core.Row;
import com.datastax.driver.core.Session;
import com.datastax.spark.connector.cql.CassandraConnector;

import static com.datastax.spark.connector.japi.CassandraJavaUtil.javaFunctions;
import static com.datastax.spark.connector.japi.CassandraJavaUtil.mapToRow;
import static com.datastax.spark.connector.japi.CassandraJavaUtil.mapRowTo;

import org.apache.spark.Logging;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TJSONProtocol;
import org.apache.log4j.*;
/**
 * Reads real-time thrift encoded FlightSummaries from a Kafka topic, 
 * joins with the latest weather data, and stores the results in Cassandra.
 *
 * Program arguments are Spark master and cassandra address and optionally
 * the Kafka server to connect with (defaults to "localhost:2181")
 */
public final class KafkaStreamingPosts implements Serializable {
	private static final Pattern SPACE = Pattern.compile(" ");
	static TDeserializer deserializer = new TDeserializer(new TJSONProtocol.Factory());
	public static void main(String[] args) {
		new KafkaStreamingPosts(args);
	}
	
	KafkaStreamingPosts(String[] args) {
		if (args.length < 2) {
			System.err.println("Usage: JavaStreamingPosts <master> <Cassandra Host> <Optional: Kafka server>");
			System.exit(1);
		}

		boolean log4jInitialized = Logger.getLogger("spark").getAllAppenders().hasMoreElements();
		 if (!log4jInitialized) {
			// We first log something to initialize Spark's default logging, then we override the
			// logging level.
			Logger.getLogger("spark").info("Setting log level to [WARN] for streaming example." +
			" To override add a custom log4j.properties to the classpath.");
			Logger.getLogger("spark").setLevel(Level.WARN);
			Logger.getRootLogger().setLevel(Level.WARN);
			}		
		// Create the context with a 1 second batch size
		final SparkConf sparkConf = new SparkConf().setAppName("StreamingPosts");
	    sparkConf.setMaster(args[0]);
		sparkConf.set("spark.cassandra.connection.host", args[1]);
		
		JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(1000));
        JavaSparkContext sc = new JavaSparkContext(sparkConf);

		// Create a JavaReceiverInputDStream on target ip:port and count the
		// words in input stream of \n delimited text (eg. generated by 'nc')
		// Note that no duplication in storage level only for running locally.
		// Replication necessary in distributed scenario for fault tolerance.
		JavaPairReceiverInputDStream<String, String> kafkaMessages 
		    = KafkaUtils.createStream(ssc, args.length > 2 ? args[2] : "localhost:2181", "1", new HashMap<String, Integer>() {
			  { put("post-submissions", 1); }
		  });
		JavaDStream<String> lines = kafkaMessages.map(new Function<Tuple2<String, String>, String>() {
			@Override
			public String call(Tuple2<String, String> tuple2) {
				return tuple2._2();
			}
		});
		JavaDStream<CassandraPostSummary> postSummaries 
		   = lines.map(new Function<String, CassandraPostSummary>() {
			@Override
			public CassandraPostSummary call(String x) {
				PostSummary postSummary = new PostSummary();
				try {
					deserializer.fromString(postSummary, x);
				} catch (TException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
				return new CassandraPostSummary(postSummary);
			}
		});
		    
		final CassandraConnector cassandraConnector = CassandraConnector.apply(sparkConf);
//        Session session = cassandraConnector.openSession();

//		JavaDStream<FlightAndWeatherSummary> flightAndWeatherSummaries
//		 = flightSummaries.map(new Function<FlightSummary, FlightAndWeatherSummary>() {
//			@Override
//			public FlightAndWeatherSummary call(final FlightSummary flightSummary) {
//				return cassandraConnector.withSessionDo(new AbstractFunction1<Session, FlightAndWeatherSummary>() {

//					@Override
//					public PostSummary apply(Session session) {
//						FlightAndWeatherSummary flightAndWeatherSummary = new FlightAndWeatherSummary();
//						flightAndWeatherSummary.setOrigin(flightSummary.origin);
//						flightAndWeatherSummary.setDest(flightSummary.dest);
//						flightAndWeatherSummary.setWhen(new Date());
//						flightAndWeatherSummary.setDelay(flightSummary.delay);
//						flightAndWeatherSummary.setFog(row.getBool("Fog"));
//						flightAndWeatherSummary.setHail(row.getBool("Hail"));
//						flightAndWeatherSummary.setRain(row.getBool("Rain"));
//						flightAndWeatherSummary.setSnow(row.getBool("Snow"));
//						flightAndWeatherSummary.setThunder(row.getBool("Thunder"));
//						flightAndWeatherSummary.setTornado(row.getBool("Tornado"));
//						return flightAndWeatherSummary; 
//					}
					
//				});
//			}
//		});

		// "weather" - name of database, "flight_and_weather" - name of table
		javaFunctions(postSummaries)
          .writerBuilder("reddit", "latest_posts", mapToRow(CassandraPostSummary.class))
          .saveToCassandra();

		ssc.start();
		ssc.awaitTermination();
	}
}
